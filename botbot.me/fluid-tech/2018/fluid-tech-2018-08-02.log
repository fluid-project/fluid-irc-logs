b"2018-08-02T20:12:53 <gmoss> well if they weren't monitoring before, they are now ;)
2018-08-02T20:15:07 <clown> d'oh!
2018-08-02T20:47:12 * cindyli has quit
2018-08-02T20:49:09 * alanharnum joined the channel
2018-08-02T21:25:19 * alanharnum has quit
2018-08-02T21:25:45 * alanharnum joined the channel
2018-08-02T21:29:34 * alanharnum has quit
2018-08-02T21:29:41 * alanharnum joined the channel
2018-08-02T21:33:59 * jhernandez has quit
2018-08-02T21:36:25 * avtar has quit
2018-08-02T21:37:13 * mrtyler joined the channel
2018-08-02T21:59:28 * cindyli joined the channel
2018-08-02T22:10:12 * colinclark_ joined the channel
2018-08-02T22:10:14 * colinclark_ is now known as colinclark
2018-08-02T22:30:49 * cindyli has quit
2018-08-02T22:41:33 * cindyli joined the channel
"

b'2018-08-02T01:12:42 * mrtyler joined the channel
2018-08-02T05:41:01 * the-t-in-rtf joined the channel
2018-08-02T05:43:14 * mrtyler joined the channel
2018-08-02T06:11:08 * jhernandez has quit
2018-08-02T06:35:08 * mrtyler has quit
2018-08-02T06:38:22 * mrtyler joined the channel
2018-08-02T06:44:26 * mrtyler has quit
2018-08-02T06:55:22 * mrtyler joined the channel
2018-08-02T08:57:37 * jhernandez joined the channel
2018-08-02T09:21:31 * jhernandez has quit
2018-08-02T09:21:46 * jhernandez joined the channel
2018-08-02T09:34:14 * jhernandez has quit
2018-08-02T09:34:34 * jhernandez joined the channel
2018-08-02T09:38:47 * jhernandez has quit
2018-08-02T09:39:07 * jhernandez joined the channel
2018-08-02T10:44:14 * jhernandez has quit
2018-08-02T10:44:43 * jhernandez joined the channel
2018-08-02T10:48:46 * jhernandez has quit
2018-08-02T10:49:00 * jhernandez joined the channel
2018-08-02T10:54:08 * jhernandez has quit
2018-08-02T10:54:29 * jhernandez joined the channel
2018-08-02T10:58:46 * jhernandez has quit
2018-08-02T10:59:01 * jhernandez joined the channel
2018-08-02T11:06:29 * Justin_o joined the channel
2018-08-02T11:13:35 * jhernandez has quit
2018-08-02T11:56:10 * cindyli joined the channel
2018-08-02T12:31:58 * gtirloni joined the channel
2018-08-02T12:33:01 * alanharnum joined the channel
2018-08-02T12:55:32 * jhernandez joined the channel
2018-08-02T12:58:05 * michelled joined the channel
2018-08-02T13:10:26 * klown joined the channel
2018-08-02T13:16:12 * simonjb joined the channel
2018-08-02T13:46:49 * avtar joined the channel
2018-08-02T14:13:46 * colinclark joined the channel
2018-08-02T14:15:33 * alanharnum has quit
2018-08-02T14:28:28 * jhernandez has quit
2018-08-02T14:32:40 * jhernandez joined the channel
2018-08-02T14:34:26 * jhernandez has quit
2018-08-02T15:01:06 * alanharnum joined the channel
2018-08-02T15:09:25 <klown> good morning cindyli
2018-08-02T15:09:41 <cindyli> hi clown
2018-08-02T15:10:01 <clown> I\'m building a docker image of my branch of univesal, and I get this warning:
2018-08-02T15:10:01 <clown> npm WARN lifecycle gpii-universal@0.3.0~postinstall: cannot run in wd %s %s (wd=%s) gpii-universal@0.3.0 node scripts/browserifyTestDependency.js && node scripts/convertPrefs.js testData/preferences/ build/dbData/snapset/ snapset && node scripts/convertPrefs.js testData/preferences/ build/dbData/user/ user && node scripts/convertPrefs.js tests/data/preferences/ build/tests/dbData/ user && node scripts/convertPrefs.js testData/prefere
2018-08-02T15:10:01 <clown> nces/demoUserPrefs/ build/dbData/demouser/ user /app
2018-08-02T15:10:28 <clown> it looks like the preferences are not converted \xe2\x80\x94 does this ring any bells?
2018-08-02T15:12:51 <cindyli> clown: what if you just run "npm run postinstall"
2018-08-02T15:13:02 <cindyli> does it give the same warning?
2018-08-02T15:13:08 * clown tries that
2018-08-02T15:13:39 * avtar has quit
2018-08-02T15:13:51 <clown> that works fine, cindyli
2018-08-02T15:14:01 * jessm joined the channel
2018-08-02T15:14:38 <cindyli> seems a permission issue - https://til.codes/npm-install-failed-with-cannot-run-in-wd-2/
2018-08-02T15:15:17 <cindyli> are you building the docker image in universal VM? or on your host machine?
2018-08-02T15:15:36 <clown> in unversal VM (as user "vagrant")
2018-08-02T15:15:53 <cindyli> how do you build?
2018-08-02T15:15:55 * clown looks at that link
2018-08-02T15:15:58 <cindyli> running docker build?
2018-08-02T15:16:18 <cindyli> i used to use ./script/vagrantCloudBasedContainers.sh to build universal docker image, which worked fine
2018-08-02T15:16:19 <clown> I did:  "docker build -t herrclown/universal ."
2018-08-02T15:17:12 <cindyli> try running ./script/vagrantCloudBasedContainers.sh in the universal branch that you want a docker image to be built
2018-08-02T15:17:18 <clown> I see.  vagrantCloudBasedContainers.sh. creates a docker image named "vagrant-universal"
2018-08-02T15:17:54 <clown> and, yes, it works all the time since I\'ve been modifying/testing it to work with the data loader docker image.
2018-08-02T15:18:13 <clown> okay, I\'ll use that image (the one created by vagrantCloudBasedContainers.sh).
2018-08-02T15:18:37 <clown> it\'s okay to use that image with AWS?
2018-08-02T15:18:56 <clown> do I need to rename it for AWS?
2018-08-02T15:21:12 <clown> Partly answering my own questions:  this seems to indicate that a name change is done at Docker Hub:  https://github.com/gpii-ops/gpii-infra/blob/master/aws/README.md#i-want-to-test-my-local-changes-to-gpii-components-in-my-cluster
2018-08-02T15:21:38 <clown> or rather the "components.conf" file.
2018-08-02T15:25:23 <cindyli> just point "components.conf" to the right docker image name
2018-08-02T15:25:38 * clown is slowly getting it...
2018-08-02T15:36:33 * colinclark has quit
2018-08-02T15:38:14 * colinclark joined the channel
2018-08-02T15:43:26 * mrtyler joined the channel
2018-08-02T15:48:29 <mrtyler> clown: looks like cindy got you sorted but fyi docker images are "build once, run anywhere" :)
2018-08-02T15:49:02 <mrtyler> so it is fine to use an image built inside your vagrant vm with your dev environment in the cloud
2018-08-02T15:58:52 * jhernandez joined the channel
2018-08-02T15:59:28 * jhernandez has quit
2018-08-02T15:59:42 * jhernandez joined the channel
2018-08-02T16:03:45 <clown> thanks mrtyler, cindyli.  Missed some of these message because of standup.  Just getting back.
2018-08-02T16:17:24 <clown> cindyli:  the docker image is made, but when I try to push it, I get:  "denied: requested access to the resource is denied".
2018-08-02T16:17:33 <clown> I\'ve looked up the error, and insured that I am logged into my docker hub account.  Is there anything else?
2018-08-02T16:17:53 <clown> the error comes from:  docker push vagrant-universal
2018-08-02T16:21:51 <cindyli> clown: i think you need to specify where to push
2018-08-02T16:22:17 <cindyli> something like: docker push docker.io/clown/vagrant-universal
2018-08-02T16:22:38 * clown tries that
2018-08-02T16:23:02 <cindyli> and you need to first tag your local docker image to the same name vagrant-universal
2018-08-02T16:23:12 <cindyli> so the push knows where to find the right source
2018-08-02T16:23:49 <cindyli> docker tag gpii/vagrant-universal http://docker.io/clown/vagrant-universal
2018-08-02T16:24:14 <clown> why clown?
2018-08-02T16:27:33 <clown> my local docker image is called "vagrant-universal".  That\'s what vagrantCloudBasedContainers.sh builds.  Also, the output from the push starts with:  "The push refers to repository [docker.io/library/vagrant-universal]"
2018-08-02T16:27:56 <clown> so, again, why "clown" and not "library" (or "vagrant")?
2018-08-02T16:38:08 <clown> Okay fixed it:  the main thing to do is, on dockerhub, create the "vagrant-universal" respository in the first place.
2018-08-02T16:39:01 <clown> thanks cindyli
2018-08-02T16:39:43 <cindyli> np. great you figured it out :)
2018-08-02T16:42:05 * colinclark has quit
2018-08-02T17:00:20 * avtar joined the channel
2018-08-02T17:08:10 * gtirloni_ joined the channel
2018-08-02T17:10:27 * gtirloni has quit
2018-08-02T17:37:09 * colinclark joined the channel
2018-08-02T17:38:44 * simonjb has quit
2018-08-02T17:50:06 * michelled joined the channel
2018-08-02T18:02:58 * alanharnum has quit
2018-08-02T18:03:24 * alanharnum joined the channel
2018-08-02T18:11:20 * jhernandez has quit
2018-08-02T18:26:47 * jhernandez joined the channel
2018-08-02T18:41:23 * alanharnum joined the channel
2018-08-02T18:55:30 * alanharnum has quit
2018-08-02T19:16:46 * alanharnum joined the channel
2018-08-02T19:21:35 * michelled has quit
2018-08-02T19:37:09 * gtirloni_ has quit
2018-08-02T19:39:27 <clown> hey cindyli.
2018-08-02T19:39:30 <clown> I\'m trying to follow the instructions for changing the dataloader, as given here: https://github.com/gpii-ops/gpii-infra/blob/master/aws/README.md#a-note-about-local-changes-and-gpii-dataloader
2018-08-02T19:40:13 <clown> first off, the command to kill the current loader gives me "job not found".  That is:  "kubectl -n gpii delete job gpii-dataloader"
2018-08-02T19:40:39 <cindyli> i never tried those commands. mrtyler, can you help ^
2018-08-02T19:40:50 <clown> then I deploy the new one, based on "cd aws/dev && rake deploy", but I can\'t tell if the new one was deployed.
2018-08-02T19:41:15 <clown> how do I query, say, the data base that created by that (my) loader?
2018-08-02T19:42:04 <clown> I did manage to execute "kubectl -n gpii logs -l app==dataloader" and saw the old dataloader logs.
2018-08-02T19:42:47 <clown> so, I\'m guessing my the redeployment/restarting the data loader didn\'t work, but I\'m not sure.
2018-08-02T19:43:05 <clown> okay cindyli, waiting for mrtyler.
2018-08-02T19:43:22 * clown hopes "mrtyler" isn\'t a synonym for "godot".
2018-08-02T19:44:52 <mrtyler> hello, reading
2018-08-02T19:45:32 <cindyli> clown: on my notes - https://docs.google.com/document/d/1xCsXtQWaiI4Wh36qWz68xczfMZAPzh7BEgrAQA7jEpM/edit#heading=h.qd8eyxgytryj
2018-08-02T19:45:41 <cindyli> there\'s a section of "Browse couchdb fauxton on the dev cluster
2018-08-02T19:45:45 <mrtyler> let me take a quick peak at the state of clown\'s cluster
2018-08-02T19:46:18 <clown> thanks cindyli, I\'ve been slowly going through that doc, but I haven\'t got that far.  skipping ahead...
2018-08-02T19:46:28 <cindyli> page 5
2018-08-02T19:48:30 <mrtyler> clown: hard to say what happened with your "job not found" without the state your cluster was in before-hand
2018-08-02T19:48:49 <mrtyler> however, things look good now. dataloader job shows status success, and i can curl http://preferences.dev-clown.gpii.net/preferences/carla
2018-08-02T19:49:27 <clown> mrtyler:  I\'ll try that, and one of the demo prefs
2018-08-02T19:50:35 <clown> yes, I can see carla, but not user one of the demo prefs;  http://preferences.dev-clown.gpii.net/preferences/226722c6-8895-40b4-9297-424b9da9c340
2018-08-02T19:53:33 <mrtyler> do the dataloader logs look like they come from your version of dataloader?
2018-08-02T19:54:05 <clown> cindyli, thanks again for the fauxton tip.  That makes things much easier.  But, looking at the database shows just the snapsets, and I suspect it\'s the old gpii-dataloader.
2018-08-02T19:54:11 <clown> mrtyler, no
2018-08-02T19:54:21 <mrtyler> well then i guess i\'d start there :)
2018-08-02T19:54:48 <clown> and where\'s "there"?  Namely, how do I get my gpii-dataloader to deploy/run?
2018-08-02T19:55:14 <clown> or, rather, what have  I done wrong so far?
2018-08-02T19:57:52 <mrtyler> nothing wrong. the system is doing what it\'s supposed to do: load data from the latest master version of dataloader
2018-08-02T19:58:31 <mrtyler> to change that behavior you want https://github.com/gpii-ops/gpii-infra/blob/master/aws/README.md#i-want-to-test-my-local-changes-to-gpii-components-in-my-cluster
2018-08-02T19:58:49 <mrtyler> and then, because dataloader is kind of special, you want https://github.com/gpii-ops/gpii-infra/blob/master/aws/README.md#a-note-about-local-changes-and-gpii-dataloader
2018-08-02T19:59:19 <clown> yes, I did the first step earlier today, and then the second step about an hour (?) ago.
2018-08-02T19:59:47 <clown> I guess I\'ll start from the top.
2018-08-02T20:01:23 <clown> quick question: should I "rake destroy; rake clobber" before starting over?
2018-08-02T20:02:16 <mrtyler> you certainly can, and if you are ever in doubt about the state of your environment, getting rid of it and starting over is often a good approach
2018-08-02T20:02:33 <mrtyler> however in this case, i would do `rake undeploy; rake clobber; rake deploy`
2018-08-02T20:03:02 <mrtyler> that leaves the underlying infrastructure (kubernetes cluster and below) alone, but removes (almost) everything running inside the cluster
2018-08-02T20:04:03 <clown> okay, thanks.  BTW, I\'ve just verified that the universal container I made earelier is up on docker hub, and has had three pulls since I put it there.  Suggestive that maybe it was deployed.
2018-08-02T20:05:16 * michelled joined the channel
2018-08-02T20:08:20 <mrtyler> either that or guccifer 2.0 is monitoring your progress ;)
2018-08-02T20:08:46 * cindyli joined the channel
2018-08-02T20:12:24 <clown> but, my name isn\'t "clinton"
2018-08-02T20:12:40 <clown> Ich heise Herr Klaun...
'

