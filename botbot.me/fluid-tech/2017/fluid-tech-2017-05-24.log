b"2017-05-24T17:05:37 * kasparnet joined the channel
2017-05-24T17:06:00 <avtar1> mrtyler: i suggest alpine to bring it line with the work that gtirloni put in for gpii containers
2017-05-24T17:06:06 <avtar1> *suggested
2017-05-24T17:06:28 <avtar1> but if the container is going to be temporary until your solution is in place then it doesn't really matter
2017-05-24T17:06:32 <amatas> I also agree with that. avtar1 anyway we could start using your actual container. And see how it performs
2017-05-24T17:06:44 <avtar1> we can start this container as-is and add the necessary webhooks
2017-05-24T17:06:46 * kasparnet has quit
2017-05-24T17:06:51 <avtar1> ok cool
2017-05-24T17:08:00 <gtirloni> thanks folks, if you need help to test stuff, i'm around
2017-05-24T17:08:37 <avtar1> i suggest maybe using one of the-t-in-rtf's repos since they get updated frequently and the jenkins pr builder won't interfere with tests there
2017-05-24T17:08:46 <gtirloni> +1
2017-05-24T17:09:32 <amatas> +1
2017-05-24T17:10:10 <avtar1> i'll follow up with the-t-in-rtf then
2017-05-24T17:10:12 <avtar1> thanks all
2017-05-24T17:10:37 <avtar1> brb
2017-05-24T17:16:34 * javjarfer has quit
2017-05-24T17:18:52 * avtar joined the channel
2017-05-24T17:31:40 * cindyli1 joined the channel
2017-05-24T17:36:42 * avtar joined the channel
2017-05-24T18:05:58 * kasparnet joined the channel
2017-05-24T18:12:41 * the-t-in-rtf has quit
2017-05-24T18:21:04 * kasparnet has quit
2017-05-24T18:25:34 * avtar joined the channel
2017-05-24T18:27:39 * kasparnet joined the channel
2017-05-24T18:32:24 * the-t-in-rtf joined the channel
2017-05-24T18:35:02 * kasparnet has quit
2017-05-24T18:36:56 * kasparnet joined the channel
2017-05-24T18:37:57 * simonjb joined the channel
2017-05-24T18:55:47 * stegru has quit
2017-05-24T18:58:40 * amatas has quit
2017-05-24T19:01:47 * colinclark joined the channel
2017-05-24T19:03:08 * kasparnet has quit
2017-05-24T19:05:48 * avtar joined the channel
2017-05-24T19:07:04 * avtar1 joined the channel
2017-05-24T19:12:50 * colinclark joined the channel
2017-05-24T19:29:03 * kasparnet joined the channel
2017-05-24T19:35:28 * stegru joined the channel
2017-05-24T19:39:14 * simonjb joined the channel
2017-05-24T19:43:15 * kasparnet has quit
2017-05-24T19:46:33 * colinclark joined the channel
2017-05-24T20:03:15 * kasparnet joined the channel
2017-05-24T20:10:36 * kasparnet has quit
2017-05-24T20:12:51 * javjarfer joined the channel
2017-05-24T20:14:23 * kasparnet joined the channel
2017-05-24T20:19:18 * kasparnet has quit
2017-05-24T20:23:14 * kasparnet joined the channel
2017-05-24T20:36:33 * kasparnet has quit
2017-05-24T21:04:01 * the-t-in-rtf has quit
2017-05-24T21:28:08 * gtirloni has quit
2017-05-24T22:43:06 * Justin_o has quit
2017-05-24T22:55:28 * stegru has quit
"

b'2017-05-24T00:34:29 * colinclark joined the channel
2017-05-24T00:53:38 * mrtyler joined the channel
2017-05-24T06:18:58 * the-t-in-rtf joined the channel
2017-05-24T07:10:59 * stegru joined the channel
2017-05-24T07:29:25 * kasparnet joined the channel
2017-05-24T07:30:00 * kasparne_ joined the channel
2017-05-24T07:33:43 * kasparnet has quit
2017-05-24T07:49:30 * javjarfer joined the channel
2017-05-24T08:23:26 * amatas joined the channel
2017-05-24T08:26:46 * kasparne_ has quit
2017-05-24T09:18:13 * kasparne_ joined the channel
2017-05-24T09:37:39 * Bosmon7 has quit
2017-05-24T09:37:55 * Bosmon7 joined the channel
2017-05-24T10:03:07 <kasparne_> Bosmon: I\'m encountering some errors in the untrusted flowmanager tests
2017-05-24T10:03:12 <kasparne_> (integration tests)
2017-05-24T10:03:28 <kasparne_> due to it attempting to use a wrong port when fetching preferences
2017-05-24T10:03:58 <kasparne_> which in itself is pretty weird, since I didn\'t change anything in the configs related to ports(!!!!!!)
2017-05-24T10:04:55 <kasparne_> anyway - I was wondering if there is a place to break and get a good overview of the final configuration used for spinning up the servers
2017-05-24T10:05:03 <kasparne_> i.e. the merged server configs
2017-05-24T10:58:07 <kasparne_> Bosmon7: Hmm... so it\'s getting weirder and weirder... after making these changes: https://github.com/GPII/universal/pull/513/commits/f3eb66c037e83fe5047ae3c11a5cb0aa820e0e2b .. I\'m getting an error related to the tests/UntrustedUserLogonStateChangeTests.js attempting to fetch preferences on port 8081
2017-05-24T11:03:18 <Bosmon7> kasparne_
2017-05-24T11:03:27 <Bosmon7> Crazy dark magic eh? : P
2017-05-24T11:05:55 <Bosmon7> You don\'t seem to have changed any of the configs at all
2017-05-24T11:06:00 <Bosmon7> So it\'s certainly puzzling
2017-05-24T11:08:45 <Bosmon7> The best place to see what configs are loaded is to up the priority on this logging message: https://github.com/fluid-project/kettle/blob/master/lib/KettleConfigLoader.js#L142
2017-05-24T11:10:29 <Bosmon7> I wonder whether what is happening is something related to renaming this grade - note this comment above here
2017-05-24T11:10:30 <Bosmon7> https://github.com/GPII/universal/pull/513/commits/f3eb66c037e83fe5047ae3c11a5cb0aa820e0e2b#diff-7b74d9cf6cbb87d85e02f681d86d5f00R145
2017-05-24T11:13:13 <kasparne_> Bosmon7: good call!
2017-05-24T11:13:36 <kasparne_> I\'ll try and do some digging there
2017-05-24T11:14:03 <kasparne_> I\'ve been going through all my changes and was really hard pressed to find any potential causes of the issue
2017-05-24T11:14:28 <kasparne_> I gotta grab a quick bite of lunch now, but will let you know what i find afterwards
2017-05-24T11:50:02 * Bosmon7 has quit
2017-05-24T12:02:53 <kasparne_> Bosmon: so turned out this line: https://github.com/GPII/universal/pull/513/commits/f3eb66c037e83fe5047ae3c11a5cb0aa820e0e2b#diff-b495ca9553a00e8dcdfdd74e69e534aaR111 was the sinner... the reference from https://github.com/GPII/universal/blob/master/gpii/node_modules/flowManager/src/UntrustedFlowManager.js#L46 wasn\'t overriding it after the change, and hence the login flow wasn\'t changed to be according to untrusted setup
2017-05-24T12:11:06 * gtirloni joined the channel
2017-05-24T12:16:27 * Justin_o joined the channel
2017-05-24T12:42:09 * kasparne_ has quit
2017-05-24T13:06:56 * cindyli joined the channel
2017-05-24T13:31:54 * avtar joined the channel
2017-05-24T13:47:39 * simonjb joined the channel
2017-05-24T13:57:40 * kasparnet joined the channel
2017-05-24T14:00:22 * kasparnet has quit
2017-05-24T14:02:43 * kasparnet joined the channel
2017-05-24T14:12:19 * kasparnet has quit
2017-05-24T14:13:49 * kasparnet joined the channel
2017-05-24T14:14:08 * kasparnet has quit
2017-05-24T14:29:49 * colinclark joined the channel
2017-05-24T14:32:11 <avtar> amatas, gtirloni: ping
2017-05-24T14:44:02 <amatas> morning
2017-05-24T14:44:10 <amatas> hi avtar
2017-05-24T14:46:29 * mrtyler joined the channel
2017-05-24T14:46:35 <avtar> hi :)
2017-05-24T14:46:57 <avtar> i had a couple questions regarding this conversation from yesterday https://botbot.me/freenode/fluid-tech/2017-05-23/?msg=86031746&page=1
2017-05-24T14:49:36 <avtar> i tried this approach last year and it accomplishes what you and gtirloni were talking about https://github.com/avtar/docker-push-ref-gitlab
2017-05-24T14:50:19 <avtar> it doesn\'t handle failures gracefully (if github or gitlab are down) but it\'s better than nothing for now
2017-05-24T14:50:48 <mrtyler> avtar: my pretty strong preference is for a pull-based rather than push-based system
2017-05-24T14:50:57 <mrtyler> for exactly the reason you just stated: handling failure
2017-05-24T14:51:17 <avtar> mrtyler: how often would we be pulling?
2017-05-24T14:51:31 <mrtyler> my standard approach is to poll every 5 minutes
2017-05-24T14:52:14 <mrtyler> in jenkins i\'ve used the H/5 trick to get some splaying
2017-05-24T14:54:30 <avtar> mrtyler: i\'m proposing that we put what i have in place since it\'ll involve spinning up a container and then if you or anyone else have improvements in mind we could refine as we go along
2017-05-24T14:54:32 <avtar> thoughts?
2017-05-24T14:55:50 <mrtyler> my concern is that adopting a pull-based mentality is important for the team and using push delays that adoption
2017-05-24T14:56:27 <mrtyler> i like the idea of a dedicated piece for facilitating communication between github and gitlab (altho it would be better if gitlab would handle this on their end of course)
2017-05-24T14:58:51 <mrtyler> just looking for other solutions in the universe: https://stackoverflow.com/questions/3669636/automatically-keep-a-secondary-repo-in-sync-with-a-primary-repo
2017-05-24T15:01:02 <mrtyler> i think this is a slightly different problem case but surely there is tooling to handle "keep repo B in sync with repo A" somewhere
2017-05-24T15:01:08 * kasparnet joined the channel
2017-05-24T15:02:35 <mrtyler> it\'s definitely possible that i\'m missing something and the solution requires more sophisticaion
2017-05-24T15:03:10 <amatas> seems that gitlab supports repository mirroring by default: https://docs.gitlab.com/ee/workflow/repository_mirroring.html
2017-05-24T15:03:24 <kasparnet> mrtyler: dont know what you\'re missing!
2017-05-24T15:03:25 <kasparnet> :)
2017-05-24T15:03:32 <mrtyler> kasparnet: yes i do :p
2017-05-24T15:03:43 <avtar> amatas, mrtyler: they support mirroring but only once per hour
2017-05-24T15:04:07 <mrtyler> also this says enterprise edition. not sure if that matters
2017-05-24T15:04:23 <mrtyler> Users with at least developer access to the project can also force an immediate update with a click of a button.
2017-05-24T15:04:36 <mrtyler> can we just automate a click on that every 5 minutes?
2017-05-24T15:04:38 <amatas> Let me check this: https://docs.gitlab.com/ee/workflow/repository_mirroring.html#adjusting-synchronization-times
2017-05-24T15:04:46 <amatas> in my local instance
2017-05-24T15:05:52 <mrtyler> 15min is still kinda slow
2017-05-24T15:06:19 <mrtyler> but possibly better than configuring a different stop-gap solution
2017-05-24T15:11:38 <avtar> amatas, mrtyler: i need to relocate to another network, brb
2017-05-24T15:11:51 * avtar has quit
2017-05-24T15:11:58 <amatas> ok
2017-05-24T15:12:17 * avtar joined the channel
2017-05-24T15:18:17 <mrtyler> i think all we need is something like:
2017-05-24T15:18:44 <mrtyler> while true ; do sleep 300 && git fetch origin && git push --mirror gitlab ; done
2017-05-24T15:19:42 <mrtyler> would need some initial git config (git clone origin; git clone gitlab; RW credentials for gitlab repo)
2017-05-24T15:19:56 <mrtyler> could run in a docker container, maaaaybe could even run in k8s
2017-05-24T15:21:12 <gtirloni> we can enhance the docker-push-ref-gitlab code with a timer to fire every X minutes, in addition to receiving pings through the hook
2017-05-24T15:22:06 <mrtyler> why do we need to support hooks?
2017-05-24T15:22:22 <gtirloni> shorter time to action
2017-05-24T15:22:32 <mrtyler> i\'d rather poll more frequently
2017-05-24T15:22:49 <gtirloni> high cpu usage (maybe not at our scale)
2017-05-24T15:23:35 <mrtyler> anecdote: i\'ve built a lot of CI systems. someone always says "we need a push to make it go faster". i say "let\'s try it with just pull". i\'ve never implemented push support
2017-05-24T15:23:54 <mrtyler> push support adds quite a bit of complexity. now you need to listen on a port on the public internet
2017-05-24T15:24:48 <mrtyler> avtar\'s existing solution requires node and ansible
2017-05-24T15:26:47 <gtirloni> agreed
2017-05-24T15:32:48 <gtirloni> re: a container and k8s -- we\'d use a cron job in that case (https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/)
2017-05-24T15:34:58 <amatas> either github and gitlab support ssh keys authentication for pulling or pushing changes, so I guess that we could use a particular ssh key for the synchronization
2017-05-24T15:52:54 <amatas> sad to see that the community edition of Gitlab doesn\'t support mirroring: https://gitlab.com/gitlab-org/gitlab-ce/issues/18732
2017-05-24T15:54:15 * avtar joined the channel
2017-05-24T15:54:15 * avtar has quit
2017-05-24T16:00:37 * kasparnet has quit
2017-05-24T16:26:53 * avtar joined the channel
2017-05-24T16:28:37 * avtar1 joined the channel
2017-05-24T16:30:25 <avtar1> amatas, gtirloni, mrtyler: i\'m catching up on the channel logs
2017-05-24T16:31:41 <avtar1> mirroring repos from github to gitlab to trigger ci jobs is the main requirement here
2017-05-24T16:32:44 <avtar1> if we want to have the same behaviour or updating github pull requests with ci job results then using the gh status api with data obtained from gitlab ci would be another requirement
2017-05-24T16:33:13 <avtar1> data for the second case is obtained using gitlab\'s build events which use webhooks
2017-05-24T16:35:39 <avtar1> this push vs pull conversation seems, to me at least, tangential to having an automated process in place today using the container i referred to earler as opposed to working out the details of putting a pull model in place
2017-05-24T16:37:13 <amatas> seems that every branch with a .gitlab-ci.yml will trigger a build every time a commit is pushed, and also the merge requests can automatically trigger the tests.
2017-05-24T16:37:29 <amatas> So I guess that we can only focus on how to synchronize the repositories
2017-05-24T16:38:18 <avtar1> amatas: that doesn\'t cover the second requirement of pushing job results to github pull request threads
2017-05-24T16:38:39 <amatas> mmm
2017-05-24T16:39:36 <amatas> I see
2017-05-24T16:40:06 <avtar1> but to focus on what can be done today that covers both requirements we could deploy this container (i can remove the ansible bits and use the alpine image to simplify things) and set up webhooks for the projects that are going to be tested with gitlab ci
2017-05-24T16:40:43 <amatas> does your container manage the webhooks?
2017-05-24T16:41:13 <avtar1> mrtyler: for this separate pull vs push conversation it seems there\'s some exploratory work required, which might warrant capturing your thoughts and task time estimates in a jira
2017-05-24T16:41:28 <avtar1> amatas: please define manage in this context :)
2017-05-24T16:42:58 <amatas> sure, sorry, I mean making the url of the build log available at the PR\'s thread of GitHub once the CI is finished.
2017-05-24T16:45:46 <avtar1> amatas: yes it does that
2017-05-24T16:46:36 <avtar1> it\'s one request to the gh statuses endpoint https://github.com/avtar/docker-push-ref-gitlab/blob/master/ansible/files/update-github-status.sh#L25
2017-05-24T16:48:10 <amatas> awesome
2017-05-24T16:48:23 <mrtyler> avtar1: i think spending time on a push-based/webhook solution is a mistake because i think a pull-based solution will take the same amount of effort
2017-05-24T16:48:38 <mrtyler> however, i\'m not the one doing this work so that is just my opinion
2017-05-24T16:49:17 <avtar1> mrtyler: i guess my point is that the time required for the webhook approach is a couple of hours to remove ansible from the container
2017-05-24T16:49:19 <mrtyler> i can write my rationale in a ticket if you think that will be helpful
2017-05-24T16:49:40 <mrtyler> avtar1: how much effort for a pull-based solution?
2017-05-24T16:49:41 <avtar1> i\'m not sure how long the other approach will take but since you\'re advocating for it i was deferring to you
2017-05-24T16:49:47 <mrtyler> ah
2017-05-24T16:50:02 <mrtyler> i would guess a similar amount of effort
2017-05-24T16:50:27 <avtar1> mrtyler: i say go for it :)
2017-05-24T16:50:46 <mrtyler> sorry i don\'t understand. go for what?
2017-05-24T16:51:08 <avtar1> exploring the pull based approach
2017-05-24T16:51:40 <mrtyler> just so i\'m clear: you\'re saying you\'re willing to spend a couple hours to implement a push-based solution, but you\'re not willing to spend any time to implement a pull-based solution?
2017-05-24T16:53:03 <avtar1> mrtyler: i\'m willing to update the container to remove ansible so that what exists now can be deployed since that seems like the most effective route to addressing yesterday\'s conversation https://botbot.me/freenode/fluid-tech/2017-05-23/?msg=86031746&page=1
2017-05-24T16:53:26 <avtar1> what has been raised today isn\'t sometihng i\'m advocating for since i\'m not sure how much time it will take
2017-05-24T16:54:00 <mrtyler> i don\'t know how to respond to that
2017-05-24T16:54:40 <mrtyler> i am happy to work on this problem if the team thinks it\'s the most important thing for me to work on
2017-05-24T16:57:24 <amatas> I think that either way push or pull would work for me as it keeps the repositories synchronized. I would vote for starting with the solution that we almost have that is the avtar1\'s container and see how it goes.
2017-05-24T16:58:37 <avtar1> mrtyler: i\'m not sure who would make that call but i\'m still suggesting to move forward with what\'s more within reach today and refine as time goes on if people feel strongly about it
2017-05-24T17:01:35 <mrtyler> i still think it is a mistake to adopt what i\'m confident is the wrong strategy, but since i am in the minority please go forward with whatever you think is best
2017-05-24T17:01:42 <gtirloni> if the terraform work can take a break and this feels important enough, i\'m find with dedicating time to experiment with that (since it seems it should take 2 hours? that\'s what i understood). i\'d love to get out of the bind we\'re in with jenkins vs gitlab and move forward with $something
2017-05-24T17:01:46 <mrtyler> i have to go register to vote because the montana dmv didn\'t register me two months ago when i asked them to
2017-05-24T17:01:49 <gtirloni> s/find/fine/
2017-05-24T17:02:37 <mrtyler> i can incorporate some exploration into my current pass through CI/CD
2017-05-24T17:02:59 <avtar1> sounds good
2017-05-24T17:03:00 <mrtyler> i guess if it\'s easy i\'ll have a working prototype, and if not then we\'ll have avtar\'s solution
2017-05-24T17:03:29 <mrtyler> thanks
2017-05-24T17:04:17 <mrtyler> fwiw i don\'t think i\'d bother with removing ansible / migrating to alpine
2017-05-24T17:04:39 <mrtyler> if the emphasis is to get something working, and you have something that works, then just deploy it?
'

