2019-01-18T00:11:54  *** jhernandez <jhernandez!~jhernande@2a02:a03f:3e55:d000:89f4:43d9:687f:fc14> has joined #fluid-work
2019-01-18T00:40:37  *** jhernandez <jhernandez!~jhernande@2a02:a03f:3e55:d000:89f4:43d9:687f:fc14> has quit IRC (Remote host closed the connection)
2019-01-18T00:41:49  *** jhernandez <jhernandez!~jhernande@2a02:a03f:3e55:d000:e031:dade:4b00:3465> has joined #fluid-work
2019-01-18T00:46:33  *** jhernandez <jhernandez!~jhernande@2a02:a03f:3e55:d000:e031:dade:4b00:3465> has quit IRC (Ping timeout: 252 seconds)
2019-01-18T01:22:26  *** kokoja <kokoja!~kokoja@87-116-79-195.ip.btc-net.bg> has joined #fluid-work
2019-01-18T01:26:50  *** kokoja <kokoja!~kokoja@87-116-79-195.ip.btc-net.bg> has quit IRC (Ping timeout: 250 seconds)
2019-01-18T01:53:03  *** fluid-bot` <fluid-bot`!~limnoria@205.211.169.46> has joined #fluid-work
2019-01-18T02:00:18  *** fluid-bot <fluid-bot!~limnoria@205.211.169.46> has quit IRC (*.net *.split)
2019-01-18T03:21:18  *** kokoja <kokoja!~kokoja@87-116-79-195.ip.btc-net.bg> has joined #fluid-work
2019-01-18T03:26:43  *** kokoja <kokoja!~kokoja@87-116-79-195.ip.btc-net.bg> has quit IRC (Ping timeout: 246 seconds)
2019-01-18T03:39:08  *** sepidehshahi <sepidehshahi!~sepidehsh@CPEe0553d68e035-CM64777d56f120.cpe.net.cable.rogers.com> has joined #fluid-work
2019-01-18T04:10:23  *** sepidehshahi <sepidehshahi!~sepidehsh@CPEe0553d68e035-CM64777d56f120.cpe.net.cable.rogers.com> has left #fluid-work
2019-01-18T04:25:22  *** colinclark <colinclark!~colinclar@cpe-67-251-79-22.stny.res.rr.com> has quit IRC (Quit: colinclark)
2019-01-18T04:26:09  *** colinclark <colinclark!~colinclar@cpe-67-251-79-22.stny.res.rr.com> has joined #fluid-work
2019-01-18T05:58:07  *** danayo <danayo!~danayo@S01069050ca694f23.vc.shawcable.net> has quit IRC (Quit: danayo)
2019-01-18T06:08:21  *** colinclark <colinclark!~colinclar@cpe-67-251-79-22.stny.res.rr.com> has quit IRC (Quit: colinclark)
2019-01-18T06:09:52  *** dandimitrov <dandimitrov!~danailbd@87.121.114.143> has joined #fluid-work
2019-01-18T06:17:33  *** dandimitrov <dandimitrov!~danailbd@87.121.114.143> has quit IRC (Quit: dandimitrov)
2019-01-18T07:35:35  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has joined #fluid-work
2019-01-18T07:41:56  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has quit IRC (Quit: dandimitrov)
2019-01-18T07:55:14  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has joined #fluid-work
2019-01-18T11:18:32  *** kokoja <kokoja!~kokoja@87-116-79-195.ip.btc-net.bg> has joined #fluid-work
2019-01-18T11:19:03  *** jhung <jhung!~Adium@tnhlon4048w-lp140-01-76-70-92-165.dsl.bell.ca> has joined #fluid-work
2019-01-18T11:24:37  *** kokoja <kokoja!~kokoja@87-116-79-195.ip.btc-net.bg> has quit IRC (Remote host closed the connection)
2019-01-18T11:25:04  *** kokoja <kokoja!~kokoja@87-116-79-195.ip.btc-net.bg> has joined #fluid-work
2019-01-18T11:29:27  *** kokoja <kokoja!~kokoja@87-116-79-195.ip.btc-net.bg> has quit IRC (Ping timeout: 264 seconds)
2019-01-18T11:55:55  *** jhung <jhung!~Adium@tnhlon4048w-lp140-01-76-70-92-165.dsl.bell.ca> has quit IRC (Quit: Leaving.)
2019-01-18T11:56:24  *** jhung <jhung!~Adium@tnhlon4048w-lp140-01-76-70-92-165.dsl.bell.ca> has joined #fluid-work
2019-01-18T12:17:11  *** jhung <jhung!~Adium@tnhlon4048w-lp140-01-76-70-92-165.dsl.bell.ca> has quit IRC (Quit: Leaving.)
2019-01-18T12:19:40  <javjarfer[m]> Hi there Bosmon ! I created this pull which should trigger the behavior form yesterdays issue!
2019-01-18T12:19:51  *** jhung <jhung!~Adium@tnhlon4048w-lp140-01-76-70-92-165.dsl.bell.ca> has joined #fluid-work
2019-01-18T12:19:53  <javjarfer[m]> please let me know if you need anything from me
2019-01-18T12:31:35  *** jhung <jhung!~Adium@tnhlon4048w-lp140-01-76-70-92-165.dsl.bell.ca> has quit IRC (Quit: Leaving.)
2019-01-18T13:00:01  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has quit IRC (Quit: dandimitrov)
2019-01-18T13:00:08  *** jhung <jhung!~Adium@CPE54a0505a5e09-CMa84e3f431590.cpe.net.cable.rogers.com> has joined #fluid-work
2019-01-18T13:15:01  *** cherylhjli <cherylhjli!~Adium@142.122.106.129> has joined #fluid-work
2019-01-18T13:17:13  *** dandimitrov <dandimitrov!~danailbd@62.44.101.75> has joined #fluid-work
2019-01-18T13:27:16  *** dandimitrov <dandimitrov!~danailbd@62.44.101.75> has quit IRC (Quit: dandimitrov)
2019-01-18T13:29:01  *** michelled <michelled!~Adium@192-0-151-7.cpe.teksavvy.com> has joined #fluid-work
2019-01-18T13:31:53  *** dandimitrov <dandimitrov!~danailbd@62.44.101.75> has joined #fluid-work
2019-01-18T13:38:11  *** dandimitrov <dandimitrov!~danailbd@62.44.101.75> has quit IRC (Quit: dandimitrov)
2019-01-18T14:03:21  *** dandimitrov <dandimitrov!~danailbd@62.44.101.75> has joined #fluid-work
2019-01-18T14:11:46  *** dandimitrov <dandimitrov!~danailbd@62.44.101.75> has quit IRC (Ping timeout: 246 seconds)
2019-01-18T14:13:10  *** simonjb <simonjb!~simonjb@198.178.118.18> has joined #fluid-work
2019-01-18T14:24:41  *** cherylhjli <cherylhjli!~Adium@142.122.106.129> has quit IRC (Quit: Leaving.)
2019-01-18T14:26:19  *** cherylhjli <cherylhjli!~Adium@142.122.106.129> has joined #fluid-work
2019-01-18T14:30:06  *** clown <clown!clown@nat/ocadu/x-litlleayuwmbegeu> has joined #fluid-work
2019-01-18T15:21:41  *** jhernandez <jhernandez!~jhernande@2a02:a03f:3e55:d000:e028:6bf8:c299:43a> has joined #fluid-work
2019-01-18T15:26:59  *** colinclark <colinclark!~colinclar@cpe-67-251-79-22.stny.res.rr.com> has joined #fluid-work
2019-01-18T15:34:19  <simonjb> hi Bosmon, I've been seeing some (2) crashes of Kettle in sjrk-story-telling-server "Error marking thread to request <ID> which has already been destroyed"
2019-01-18T15:34:34  <simonjb> I've filed at JIRA with some logs: https://issues.fluidproject.org/browse/SJRK-187
2019-01-18T15:34:50  <simonjb> both times were on node 10.15.0
2019-01-18T15:35:10  <simonjb> we are using Kettle 1.8.0 (not 1.9.0)
2019-01-18T15:35:51  <Bosmon> Thanks for the report, simonjb
2019-01-18T15:35:54  <Bosmon> What do you mean by "crash"?
2019-01-18T15:36:03  <simonjb> process terminates
2019-01-18T15:36:04  <Bosmon> Do you mean, abort an active request?
2019-01-18T15:36:15  <Bosmon> I see, that's pretty odd
2019-01-18T15:36:34  <Bosmon> Do you see the error reported only once during the whole session just before the crash?
2019-01-18T15:36:40  <simonjb> yes
2019-01-18T15:36:49  <Bosmon> That's also odd
2019-01-18T15:37:39  <simonjb> I've not been able to reliably reproduce at this point
2019-01-18T15:38:30  <Bosmon> Hmm, perhaps it's not so odd, given I think I remember upgrading an unguarded fluid.fail to an uncaught exception at some point recently
2019-01-18T15:38:40  <simonjb> do you have any suggestions of things to look at that might be problematic use of Kettle maybe?
2019-01-18T15:39:04  <simonjb> this is the code: https://github.com/fluid-project/sjrk-story-telling-server/tree/learning-to-learn
2019-01-18T15:39:20  <simonjb> have we been running Kettle much on Node 10 yet?
2019-01-18T15:40:32  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-xitwcqbcdznbnduw> has quit IRC (Remote host closed the connection)
2019-01-18T15:40:41  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-sbspnbxcypojhfuw> has joined #fluid-work
2019-01-18T15:41:06  <Bosmon> simonjb - yes, the GPII has been on node 10 for a fair while
2019-01-18T15:41:23  <simonjb> good to know Bosmon
2019-01-18T15:42:21  <Bosmon> simonjb - this error will most likely be caused by there being two or more handlers which consider that they are the appropriate handler for a request, one which handles the request synchronously and the other asynchronously
2019-01-18T15:43:18  <Bosmon> It seems that you have three different handlers bound to "/*" which creates some potential for this
2019-01-18T15:43:42  <simonjb> excellent, that's a good place to start
2019-01-18T15:43:51  <Bosmon> I see two of them have different prefixes
2019-01-18T15:44:20  <Bosmon> So the likelihood seems to be that the "uiHandler" is conflicting with one of the others
2019-01-18T15:44:49  <Bosmon> I think if you apply fluid.setLogging(true) the actual path of the request causing the error should be logged before the failure
2019-01-18T15:45:30  <Bosmon> Yes, I think I remember that in earlier versions of Kettle, an uncaught fluid.fail would just silently continue, but I considered that this gave an undesirable lack of evidence of design problems : P
2019-01-18T15:45:31  <simonjb> Bosmon: in terms of reproducing, do you have recommendations for increasing the incidence? lots of traffic?
2019-01-18T15:45:42  <Bosmon> simonjb - the failure isn't deterministic?
2019-01-18T15:45:44  <Bosmon> That's odd too
2019-01-18T15:46:01  <simonjb> Bosmon: it doesn't appear to be
2019-01-18T15:47:26  <Bosmon> I guess the fact that the last handler that was allocated was "sjrk.storyTelling.server.uiHandler" adds weight to the idea that it is a conflict caused by the routing of that handler, which might somehow be considering it can grab every request?
2019-01-18T15:47:42  <simonjb> could be
2019-01-18T15:47:45  <Bosmon> It would certainly be helpful to have enough logging to know what the URL of the failing request is
2019-01-18T15:48:19  <simonjb> ok, I will add some logging and try to reproduce with some reliability
2019-01-18T15:48:39  <Bosmon> If you can point me to the current impl of the uiHandler I could see if it gives me any other ideas
2019-01-18T15:49:03  <simonjb> let me look, I don't know this code very well myself yet
2019-01-18T15:49:25  <Bosmon> As well as getting some insight into what the strategy is behind allocating it to every GET request that the server receives
2019-01-18T15:50:27  <alanharnum> Bosmon simonjb: I suspect the strategy is "alanharnum's failure to set up routes properly", as the one who authored most of it
2019-01-18T15:52:10  <alanharnum> simonjb, this goes to some of our talk a few days ago on problematic coupling - since the app is both serving a static UI, and the API for managing persistence via couch and file upload
2019-01-18T15:52:57  <Bosmon> alanharnum - well, it could do that - just at different routes : P
2019-01-18T15:53:10  <Bosmon> But I guess you wanted the root URL to do something useful
2019-01-18T15:53:15  <alanharnum> Yes.
2019-01-18T15:54:13  <Bosmon> But in general I think it is better to do that via other means, since mangling things into the same URL space invariably creates problems at other layers of the application
2019-01-18T15:54:25  <alanharnum> As I recall (and it's unfortunately been a while), what I wanted to achieve was "all requests are handled by the uiHandler, except those that hit a more specific route".
2019-01-18T15:56:31  <alanharnum> The combination of route "/*" and specific prefixes was the only way I was able to achieve this - I can't remember what else I tried in this regard
2019-01-18T15:56:35  <Bosmon> ok
2019-01-18T15:56:41  <Bosmon> Can link to the current code?
2019-01-18T15:58:20  <simonjb> thanks very much Bosmon for helping us with this
2019-01-18T15:58:33  <Bosmon> No worries, I'm just sorry that the error is so opaque and unhelpful
2019-01-18T15:58:41  <Bosmon> In addition to being intermittent : P
2019-01-18T15:58:48  <Bosmon> "This should never happen"
2019-01-18T15:59:37  <Bosmon> aka "That can never happen"
2019-01-18T16:03:30  <simonjb> alanharnum: is it possible that this is happening on the public servers but we are automatically re-starting the node process?
2019-01-18T16:03:55  <simonjb> would we have logs that could tell us?
2019-01-18T16:10:01  <alanharnum> simonjb: it's definitely possible, I believe the containers are all set to auto-restart
2019-01-18T16:10:31  <alanharnum> checked to confirm, yes, that's the case in the production environment
2019-01-18T16:12:41  <simonjb> alanharnum: confirmed that they are set to auto-restart? do we know if we have done any restarts?
2019-01-18T16:15:20  <alanharnum> simonjb: It's hard to say over the long term, as they're rebuilt and restarted nightly as part of the clean-up job
2019-01-18T16:15:27  <simonjb> got it
2019-01-18T16:15:39  <Bosmon> simonjb - it looks like the "ui" handler, like the ones it might conflict with, is also just a static handler - https://github.com/fluid-project/sjrk-story-telling-server/blob/learning-to-learn/src/js/serverSetup.js#L107
2019-01-18T16:15:43  <alanharnum> if they were crashing and restarting under usage, that might explain some of the issues we saw testing in the design crit on Tuesday
2019-01-18T16:16:07  <Bosmon> This thickens the plot a bit : P
2019-01-18T16:16:19  <Bosmon> I think still the next best clue we could get is what one of the failing URLs looks like
2019-01-18T16:16:58  <simonjb> I'm going to focus now on reproducing, will let you know when I find
2019-01-18T16:18:09  <alanharnum> simonjb: the container has stayed up since the nightly restart, but if this is a crash that only occurs under usage, or intermittently, that might not tell us much
2019-01-18T16:24:35  <Bosmon> It seems possible that this is actually a failure that is deterministic, but only triggered upon a particular URL or condition of the filesystem
2019-01-18T16:25:05  <Bosmon> I can't really think of a way off the top of my head that it could be a load-dependent bug, but it is always possible
2019-01-18T16:46:55  <Bosmon> I can think of ways that browser environments might convert asynchronous operations to synchronous ones by satisfying them from the cache, but not in node
2019-01-18T16:57:41  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-sbspnbxcypojhfuw> has quit IRC (Remote host closed the connection)
2019-01-18T16:58:10  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-ljdoznaefctoxnzm> has joined #fluid-work
2019-01-18T16:59:05  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-ljdoznaefctoxnzm> has quit IRC (Remote host closed the connection)
2019-01-18T16:59:14  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-utiegwwfpkngytkw> has joined #fluid-work
2019-01-18T16:59:17  *** colinclark <colinclark!~colinclar@cpe-67-251-79-22.stny.res.rr.com> has quit IRC (Quit: colinclark)
2019-01-18T17:31:12  <stegru> jhernandez, the file used for the reset switch seems to be incorrect: https://github.com/GPII/universal/blob/master/gpii/node_modules/flowManager/src/DefaultSettingsLoader.js#L24 vs https://github.com/GPII/universal/tree/master/testData/defaultSettings
2019-01-18T17:31:55  <stegru> which means, it appears all the reset does it key-out - unless there's already a defaultSettings file in the settings directory
2019-01-18T17:33:32  <jhernandez> %gpii-universal/testData/defaultSettings/defaultSettings.json5 is included in the installer
2019-01-18T17:33:56  <stegru> oh!
2019-01-18T17:35:13  <jhernandez> and it should be enough, as far as I know and according to the documentation here: https://github.com/GPII/universal/blob/master/documentation/ResetComputer.md#define-the-default-settings-file
2019-01-18T17:35:33  <jhernandez> and the last piece is https://github.com/GPII/universal/blob/master/documentation/ResetComputer.md#reset-on-system-start
2019-01-18T17:35:43  <jhernandez> as you can see, we're using the production config
2019-01-18T17:36:02  <jhernandez> and hey, reset to STD at startup works for me
2019-01-18T17:36:05  <jhernandez> :)
2019-01-18T17:36:08  <jhernandez> and for Kavya
2019-01-18T17:36:49  <jhernandez> here's the production config we use in gpii-app https://github.com/GPII/gpii-app/blob/master/configs/app.base.json#L25
2019-01-18T17:37:13  <jhernandez> so, what is happening is that G's computer is a bit rotten
2019-01-18T17:37:29  <jhernandez> okay
2019-01-18T17:37:30  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-utiegwwfpkngytkw> has quit IRC (Remote host closed the connection)
2019-01-18T17:37:31  <jhernandez> hold a sec
2019-01-18T17:37:49  <stegru> yes, I agree
2019-01-18T17:37:59  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-ukaxbqxvaexbsmuh> has joined #fluid-work
2019-01-18T17:39:12  <jhernandez> nevermind, I thought that probably the reset to STD file was guilty, but it looks okay to me
2019-01-18T17:39:51  <jhernandez> and btw, this is the reset to STD file we're shipping with the installer https://github.com/GPII/universal/blob/master/testData/defaultSettings/defaultSettings.win32.json5#L7
2019-01-18T17:41:42  *** jhernand_ <jhernand_!~jhernande@2a02:a03f:3e55:d000:7cd2:bda:6fde:77bd> has joined #fluid-work
2019-01-18T17:44:55  *** jhernandez <jhernandez!~jhernande@2a02:a03f:3e55:d000:e028:6bf8:c299:43a> has quit IRC (Ping timeout: 250 seconds)
2019-01-18T17:53:03  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-ukaxbqxvaexbsmuh> has quit IRC (Remote host closed the connection)
2019-01-18T17:53:13  *** alanharnum2 <alanharnum2!alanharnum@nat/ocadu/x-imjhyycttzbixzcj> has joined #fluid-work
2019-01-18T17:59:06  *** kokoja <kokoja!~kokoja@87-116-79-195.ip.btc-net.bg> has joined #fluid-work
2019-01-18T18:03:23  *** kokoja <kokoja!~kokoja@87-116-79-195.ip.btc-net.bg> has quit IRC (Ping timeout: 245 seconds)
2019-01-18T18:09:39  *** cherylhjli <cherylhjli!~Adium@142.122.106.129> has quit IRC (Quit: Leaving.)
2019-01-18T18:21:07  *** jhung <jhung!~Adium@CPE54a0505a5e09-CMa84e3f431590.cpe.net.cable.rogers.com> has quit IRC (Quit: Leaving.)
2019-01-18T18:33:48  *** sepidehshahi <sepidehshahi!sepidehsha@nat/ocadu/x-purastkejqdlocji> has joined #fluid-work
2019-01-18T18:39:38  *** simonjb <simonjb!~simonjb@198.178.118.18> has quit IRC ()
2019-01-18T18:57:27  *** alanharnum2 <alanharnum2!alanharnum@nat/ocadu/x-imjhyycttzbixzcj> has quit IRC (Remote host closed the connection)
2019-01-18T18:57:59  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-upvzocandhbcfbyl> has joined #fluid-work
2019-01-18T19:00:14  *** cherylhjli <cherylhjli!~Adium@205.211.168.101> has joined #fluid-work
2019-01-18T19:10:38  *** jhernand_ <jhernand_!~jhernande@2a02:a03f:3e55:d000:7cd2:bda:6fde:77bd> has quit IRC (Remote host closed the connection)
2019-01-18T19:36:47  <Bosmon> Hey there sgithens - how is your Capture pull doing for bryan_ ?
2019-01-18T19:36:57  *** colinclark <colinclark!~colinclar@cpe-67-251-79-22.stny.res.rr.com> has joined #fluid-work
2019-01-18T19:46:00  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-upvzocandhbcfbyl> has quit IRC (Remote host closed the connection)
2019-01-18T19:46:13  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-vojlkcumylcqklrf> has joined #fluid-work
2019-01-18T19:50:21  *** colinclark <colinclark!~colinclar@cpe-67-251-79-22.stny.res.rr.com> has quit IRC (Quit: colinclark)
2019-01-18T19:58:00  <bryan_> There's no rush...I got started with the docs, and I'm fixing that PR for GPII-3596 at the moment
2019-01-18T20:18:55  <sgithens> bryan_ Bosmon: Good, I pushed up my current work here:  https://github.com/sgithens/gpii-app/tree/GPII-1908
2019-01-18T20:19:10  <sgithens> I'm working on wrapping up cindyli's responses to my prefs server work at the moment
2019-01-18T20:21:53  <sgithens> I just made a WIP PR so it's easier to find   https://github.com/GPII/gpii-app/pull/83
2019-01-18T20:26:00  *** cherylhjli <cherylhjli!~Adium@205.211.168.101> has quit IRC (Quit: Leaving.)
2019-01-18T20:27:41  <gmoss> michelled: are you able to review PR's for fluid-project? I made a little one to merge some outstanding styling updates I'd made on tuesday. I'd like to work on SJRK-190 and 191, but it would be good to start from what's currently in my 174 branch, as some of that work would be duplicated otherwise
2019-01-18T20:28:11  <gmoss> some of the changes were made in haste, so I apologize that they aren't so DRY
2019-01-18T20:28:56  <michelled> sure gmoss - send me the links
2019-01-18T20:29:16  <gmoss> michelled: awesome! thank you :) here's the PR https://github.com/fluid-project/sjrk-story-telling/pull/5
2019-01-18T20:29:27  <bryan_> I'll take a look at that PR later
2019-01-18T20:40:15  *** jhernandez <jhernandez!~jhernande@2a02:a03f:3e55:d000:e5c1:1822:7d3b:7b67> has joined #fluid-work
2019-01-18T20:42:14  *** cherylhjli <cherylhjli!Adium@nat/ocadu/x-selcgailydavgkma> has joined #fluid-work
2019-01-18T20:51:19  *** jhernandez <jhernandez!~jhernande@2a02:a03f:3e55:d000:e5c1:1822:7d3b:7b67> has quit IRC (Remote host closed the connection)
2019-01-18T20:54:24  <michelled> gmoss: do I need to test your pull request before merging?
2019-01-18T20:55:31  <gmoss> michelled: it couldn't hurt, though the changes are pretty straightforward
2019-01-18T20:55:57  <gmoss> the server won't be affected by this, as that project is pinned to a particular commit in the branch I'd like to merge into
2019-01-18T21:07:29  <michelled> gmoss: my system is not set up to test this project right now and I have a bunch of SJRK things I need to do - can your pull request wait until Monday?
2019-01-18T21:07:32  <michelled> or can you test it?
2019-01-18T21:08:08  <gmoss> michelled: sure, I can test it. and yes it can wait until Monday. what's currently publicly hosted doesn't incorporate these changes either
2019-01-18T21:08:24  <gmoss> i just figured it might make development easier :)
2019-01-18T21:09:02  <michelled> you could merge it into your development branch and put a note on any new pull that the other one should be put in first
2019-01-18T21:09:15  *** colinclark <colinclark!~colinclar@cpe-67-251-79-22.stny.res.rr.com> has joined #fluid-work
2019-01-18T21:29:16  <gmoss> michelled: okay, I may do that, then. Thanks!
2019-01-18T21:30:53  *** sepidehshahi <sepidehshahi!sepidehsha@nat/ocadu/x-purastkejqdlocji> has quit IRC (Ping timeout: 245 seconds)
2019-01-18T21:39:46  *** jhernandez <jhernandez!~jhernande@129.53-136-217.adsl-dyn.isp.belgacom.be> has joined #fluid-work
2019-01-18T21:40:48  *** jhernandez <jhernandez!~jhernande@129.53-136-217.adsl-dyn.isp.belgacom.be> has quit IRC (Remote host closed the connection)
2019-01-18T21:56:02  *** michelled <michelled!~Adium@192-0-151-7.cpe.teksavvy.com> has quit IRC (Quit: Leaving.)
2019-01-18T22:02:11  *** clown <clown!clown@nat/ocadu/x-litlleayuwmbegeu> has quit IRC (Quit: Leaving.)
2019-01-18T22:46:48  *** alanharnum <alanharnum!alanharnum@nat/ocadu/x-vojlkcumylcqklrf> has quit IRC ()
2019-01-18T23:00:50  *** cherylhjli <cherylhjli!Adium@nat/ocadu/x-selcgailydavgkma> has quit IRC (Ping timeout: 246 seconds)
