2018-10-10T00:07:26  *** jhernandez_ <jhernandez_!~jhernande@2a02:a03f:3ea7:d200:78c2:67f9:e3a9:354c> has quit IRC (Quit: jhernandez_)
2018-10-10T01:47:00  *** fluid-bot <fluid-bot!~limnoria@205.211.169.46> has joined #fluid-work
2018-10-10T01:51:43  *** gtirloni_ <gtirloni_!gtirloni@gateway/web/irccloud.com/session> has quit IRC (Changing host)
2018-10-10T01:51:43  *** gtirloni_ <gtirloni_!gtirloni@gateway/web/irccloud.com/x-emeavdygbgzblynl> has joined #fluid-work
2018-10-10T07:04:42  *** jhernandez_ <jhernandez_!~jhernande@2a02:a03f:3ea7:d200:78c2:67f9:e3a9:354c> has joined #fluid-work
2018-10-10T07:04:44  *** jhernandez_ <jhernandez_!~jhernande@2a02:a03f:3ea7:d200:78c2:67f9:e3a9:354c> has quit IRC (Remote host closed the connection)
2018-10-10T07:04:55  *** jhernandez_ <jhernandez_!~jhernande@2a02:a03f:3ea7:d200:78c2:67f9:e3a9:354c> has joined #fluid-work
2018-10-10T07:20:57  *** the-t-in-rtf1 <the-t-in-rtf1!~Adium@2a02:a210:2142:3480:2d64:8796:2606:ea24> has quit IRC (Quit: Leaving.)
2018-10-10T07:44:32  *** georgitodorov <georgitodorov!~georgitod@37.157.190.158> has joined #fluid-work
2018-10-10T07:52:29  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has joined #fluid-work
2018-10-10T09:12:48  <georgitodorov> Bosmon: Hey, Antranig! Quick question: Can "jqUnit.expectFrameworkDiagnostic" be used together with other jqUnit.assert statements (e.g. jqUnit.assert, jqUnit.assetTrue)?
2018-10-10T09:13:28  <georgitodorov> I have 1 test which uses jqUnit.expectFrameworkDiagnostic and another one which is just a jqUnit.assert. If run separately, everything is fine
2018-10-10T09:13:54  <georgitodorov> If run together, I get an error: "Expected 2 assertions but 3 were run". Any ideas?
2018-10-10T09:15:13  <Bosmon> georgitodorov - it can, you just need to issue a jqUnit.expect count for any additional assertions you make
2018-10-10T09:15:33  <Bosmon> The rule is, if any jqUnit.expect is issued, the total count must be correct - if you issue none, it doesn't matter
2018-10-10T09:15:44  <Bosmon> And expectFrameworkDiagnostic issues one for its own count of 2 assertions
2018-10-10T09:29:01  *** the-t-in-rtf <the-t-in-rtf!~Adium@212.78.169.180> has joined #fluid-work
2018-10-10T09:57:01  <georgitodorov> Bosmon: I see, thanks!
2018-10-10T09:57:44  <georgitodorov> the-t-in-rtf: Hey, Tony! Any ideas what is causing the build hang that we talked about yesterday? Or, how it can be debugged?
2018-10-10T09:58:24  <the-t-in-rtf> honestly, not really.
2018-10-10T09:58:36  <the-t-in-rtf> my first thought is, was it something transient, i.e. the CI system acting up.
2018-10-10T09:58:46  <the-t-in-rtf> have subsequent builds had the same problems?
2018-10-10T10:07:33  <georgitodorov> the-t-in-rtf: I will be pushing shortly and we can see what happens then. There were no subsequent builds for our PR.
2018-10-10T10:08:25  <the-t-in-rtf> link to the PR?
2018-10-10T10:08:29  <the-t-in-rtf> I want to check a couple of ideas.
2018-10-10T10:09:02  <georgitodorov> the-t-in-rtf: Here it is: https://github.com/GPII/gpii-app/pull/62
2018-10-10T10:10:18  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has quit IRC (Quit: dandimitrov)
2018-10-10T10:11:07  <the-t-in-rtf> OK, I'm trying it from my OS X machine to see if I can replicate.
2018-10-10T10:11:11  <the-t-in-rtf> if I can, I have ideas.
2018-10-10T10:11:26  <the-t-in-rtf> if I can't, then we keep scratching our heads until a new idea pops out or we have more data.
2018-10-10T10:12:05  <georgitodorov> the-t-in-rtf: Sounds like a plan. Thank you, Tony!
2018-10-10T10:12:41  <the-t-in-rtf> happy to help, I hate these kinds of problems, they're miserable to work on on your own.
2018-10-10T10:13:37  <georgitodorov> the-t-in-rtf: If we can help you in some way, let us know
2018-10-10T10:14:48  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has joined #fluid-work
2018-10-10T10:38:07  <jhernandez_> georgitodorov: FYI, yesterday I got similar results locally
2018-10-10T10:38:54  <jhernandez_> this is, not returning after tests are done
2018-10-10T10:44:01  <georgitodorov> jhernandez_, the-t-in-rtf: Did you perform the tests in a VM? Is there anything special about your set-up?
2018-10-10T10:44:18  <the-t-in-rtf> do you use macs or PCs?
2018-10-10T10:44:34  <the-t-in-rtf> usually mine is special in comparison with people using Windows.
2018-10-10T10:44:44  <the-t-in-rtf> (I use a Mac)
2018-10-10T10:44:48  <jhernandez_> georgitodorov: I use the vagrant box
2018-10-10T10:44:53  <the-t-in-rtf> that doesn't matter.
2018-10-10T10:44:56  <jhernandez_> the same as CI
2018-10-10T10:44:58  <the-t-in-rtf> the host environment is important.
2018-10-10T10:45:06  <the-t-in-rtf> get that right out of your head, @jhernandez_
2018-10-10T10:45:18  <the-t-in-rtf> the host environment still matters, although it shouldn't
2018-10-10T10:45:30  <jhernandez_> why does it matter?
2018-10-10T10:45:33  <the-t-in-rtf> it's small differences, but it comes up often enough to keep an eye out for
2018-10-10T10:45:46  <the-t-in-rtf> the underlying filesystem the repo's code lives in is on the host machien
2018-10-10T10:46:13  <the-t-in-rtf> so it differs subtly depending on whether the host is linux, windows, OS X.
2018-10-10T10:46:45  <the-t-in-rtf> the reason I wanted to run the tests locally is I noticed they were running in the UNC mount on c:/vagrant
2018-10-10T10:47:00  <the-t-in-rtf> I wanted to see if I could reproduce the hang running there.
2018-10-10T10:47:12  <the-t-in-rtf> and then see if the problem went away running on the network drive on v:/
2018-10-10T10:48:05  <the-t-in-rtf> my guess is that some of the UNC issues aren't as visible if the host OS is also Windows.
2018-10-10T10:48:12  <the-t-in-rtf> but there are other issues that are always visible.
2018-10-10T10:49:26  <jhernandez_> the UNC path might be the source of the problem, but I don't see why a VM running on windows or linux or mac makes a real difference as soon as the source code is there
2018-10-10T10:50:00  <jhernandez_> (only talking about the problem we have right now)
2018-10-10T10:50:17  <jhernandez_> I ran the tests inside the vm (without the winrm plugin) and got the same results
2018-10-10T10:50:50  <Bosmon> stegru, I've merged the windows part of GPII-2869
2018-10-10T10:51:30  <Bosmon> I noticed that most of appZoom doesn't have test coverage.... could you think of any reasonable way that this could ever be tested?
2018-10-10T10:51:47  <Bosmon> It would be nice to at least have most of the code executed, even if it doesn't necessarily do anything in particular
2018-10-10T10:52:17  <the-t-in-rtf> where did you run the tests from, @jhernandez_?
2018-10-10T10:52:27  <the-t-in-rtf> c:/vagrant?
2018-10-10T10:52:33  <jhernandez_> yes
2018-10-10T10:52:35  <jhernandez_> as always
2018-10-10T10:52:37  <jhernandez_> :)
2018-10-10T10:52:38  <the-t-in-rtf> !
2018-10-10T10:52:40  <the-t-in-rtf> NOOOOO
2018-10-10T10:52:46  <Bosmon> NOOOOOOO!
2018-10-10T10:52:47  <the-t-in-rtf> I have surely ranted about this enough by now.
2018-10-10T10:52:49  <Bosmon> KHAAAAANNN!
2018-10-10T10:52:55  <the-t-in-rtf> v for victory, man.
2018-10-10T10:53:12  <jhernandez_> why should I use a remote path when I'm inside the VM? tthat's stupid IMVVVHO
2018-10-10T10:53:13  <the-t-in-rtf> so, I just got enough space free to finish setting up a VM, but maybe you can save me a little time
2018-10-10T10:53:15  <jhernandez_> xDDDD
2018-10-10T10:53:18  <the-t-in-rtf> try v:
2018-10-10T10:53:26  <Bosmon> jhernandez_ - "Because it doesn't work"
2018-10-10T10:53:27  <the-t-in-rtf> you should use it because c:/vagrant is broken
2018-10-10T10:53:48  <the-t-in-rtf> As soon as I get any bandwidth I will work to get rid of it for the common good.
2018-10-10T10:53:50  <jhernandez_> the only thing that doesn't work is the coverage thing
2018-10-10T10:53:55  <the-t-in-rtf> nope
2018-10-10T10:54:01  <the-t-in-rtf> the only thing that doesn't work THIS TIME is the coverage
2018-10-10T10:54:16  <the-t-in-rtf> there are other issues.
2018-10-10T10:56:22  <the-t-in-rtf> Anyway, I'm a few steps behind you, just confirming that I get the hang in c:/vagrant
2018-10-10T10:56:43  <the-t-in-rtf> there are provisioning steps that run from c:/vagrant, I might need to rerun those before running from v:/ depending
2018-10-10T10:56:51  <the-t-in-rtf> trying to remember the pain points from the coverage work
2018-10-10T10:57:05  <stegru> Bosmon, I'll see what I can do about the appZoom coverage.
2018-10-10T10:59:09  <stegru> c:\vagrant isn't "broken" - it's the applications that don't support it that are broken :)
2018-10-10T11:00:21  <the-t-in-rtf> ha.  Even if we bought PCs for all of the affected devs, we'd still have to convince them it was worth fixing.
2018-10-10T11:00:51  <the-t-in-rtf> I mean, something like "sharp", which fails on UNC paths is not written on a PC and not with Windows in mind.
2018-10-10T11:01:35  <the-t-in-rtf> not that anyone else uses that, but it's the first example that comes to mind.
2018-10-10T11:01:41  <the-t-in-rtf> npm itself also has troubles
2018-10-10T11:01:43  <stegru> sounds like gpii
2018-10-10T11:01:51  <the-t-in-rtf> and if they can't be bothered with their giant install base, we don't have much hope.
2018-10-10T11:02:05  <the-t-in-rtf> I mean, we have to disable global links because of the UNC paths.
2018-10-10T11:02:13  <the-t-in-rtf> they just work on v:/
2018-10-10T11:03:25  <stegru> it may be possible to just point c:/vagrant to v:/, during the transition
2018-10-10T11:03:38  <the-t-in-rtf> we can try it.
2018-10-10T11:03:54  <the-t-in-rtf> My idea was to put a directory with a polite README in c:/vagrant
2018-10-10T11:04:32  <the-t-in-rtf> or perhaps a small repo that puts up an ASCII drawing that says, "go to v:, friend"
2018-10-10T11:04:38  <the-t-in-rtf> when you run npm commands from there
2018-10-10T11:06:47  <jhernandez_> honestly, I've never understood the problems around c:\vagrant vs v:\ since we've always been running the tests from c:\vagrant until the coverage thing landed
2018-10-10T11:06:57  <jhernandez_> I remember problems in infusion with unc paths
2018-10-10T11:07:14  <the-t-in-rtf> well, there were other problems, we had just already papered over them.
2018-10-10T11:07:34  <the-t-in-rtf> I mean, configuring npm to not install global binaries is also a byproduct of running in c:/vagrant
2018-10-10T11:08:04  <the-t-in-rtf> we just got it working despite the shortcomings and moved on until there was a big enough reason to switch.
2018-10-10T11:08:22  <the-t-in-rtf> and IMO being able to reliably report coverage is enough reason to switch.
2018-10-10T11:09:09  <the-t-in-rtf> And as we've discussed in architecture meetings, there is no use case for actually supporting UNC.
2018-10-10T11:09:19  <the-t-in-rtf> it's just an artifact of how our VMs were set up.
2018-10-10T11:10:38  <the-t-in-rtf> so, infuriatingly, the coverage doesn't hang for me in c:/vagrant.  How did it work out for you, @jhernandez_?
2018-10-10T11:10:57  <the-t-in-rtf> did switching help?
2018-10-10T11:11:09  <jhernandez_> the-t-in-rtf: running now
2018-10-10T11:11:12  <the-t-in-rtf> thanks.
2018-10-10T11:11:25  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has quit IRC (Quit: dandimitrov)
2018-10-10T11:12:07  <the-t-in-rtf> I'm trying another run to see if the hang is intermittent.
2018-10-10T11:12:28  <the-t-in-rtf> unlike universal, this one takes less than a minute, so you can run it a few times
2018-10-10T11:24:12  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has joined #fluid-work
2018-10-10T11:27:39  <jhernandez_> georgitodorov, dandimitrov: BTW, I've testing the update to node10/electron 3
2018-10-10T11:28:13  <jhernandez_> *I've been
2018-10-10T11:29:00  <jhernandez_> here's the overall status: https://issues.gpii.net/browse/GPII-3438
2018-10-10T11:29:51  <jhernandez_> just in case you want to give it a try, but I'm not getting the same results locally as in CI
2018-10-10T11:30:00  *** yuriy <yuriy!~yuriy@37.157.190.158> has joined #fluid-work
2018-10-10T11:32:40  <jhernandez_> okay, v: for victory
2018-10-10T11:32:50  <jhernandez_> it didn't hang
2018-10-10T11:33:05  <jhernandez_> :D
2018-10-10T11:33:07  <the-t-in-rtf> It's really bizarre, I can't get it to hang in c:/vagrant, but it's something to try.
2018-10-10T11:33:23  <jhernandez_> yeah, very weird
2018-10-10T11:33:29  <the-t-in-rtf> pro tip, you can test just the coverage reporting using npm run posttest
2018-10-10T11:33:36  <the-t-in-rtf> so you don't have to wait for a full run.
2018-10-10T11:34:21  <jhernandez_> in fact, I have different results from my last run on CI
2018-10-10T11:34:37  <jhernandez_> (nothing new here)
2018-10-10T11:35:02  <the-t-in-rtf> in-teresting.
2018-10-10T11:35:12  <jhernandez_> let me try again on c:\vagrant if I now get the hang
2018-10-10T11:35:13  <the-t-in-rtf> I didn't think anything had hung but I can't seem to exit that powershell session.
2018-10-10T11:35:38  <dandimitrov> jhernandez_: Thanks, we were meaning to try them out as soon as we’ve finished with tests
2018-10-10T11:36:08  <jhernandez_> the-t-in-rtf: then you get the hang
2018-10-10T11:36:39  <jhernandez_> it's not a "hang", it's just that it doesn't returns
2018-10-10T11:36:45  <the-t-in-rtf> interesting.
2018-10-10T11:36:54  <the-t-in-rtf> I couldn't get it to hang up with a single run of the coverage
2018-10-10T11:37:04  <the-t-in-rtf> perhaps there's something earlier in a full run that won't release when run from c:/vagrant
2018-10-10T11:38:01  <the-t-in-rtf> I think the coverage may be a red herring.
2018-10-10T11:38:03  <jhernandez_> in CI, it leads to an error because we're calling the tests through the winrm plugin, which is not getting any return (and times out)
2018-10-10T11:38:17  <the-t-in-rtf> i.e. I think it's something left over from the test run.
2018-10-10T11:38:33  <the-t-in-rtf> I can run npm run posttest ten times and still exit the powershell
2018-10-10T11:38:37  <jhernandez_> can't tell, really
2018-10-10T11:38:40  * jhernandez_ shrugs
2018-10-10T11:38:45  <the-t-in-rtf> gonna try to narrow it down.
2018-10-10T11:39:16  <the-t-in-rtf> (once I confirm that I consistently see the hang)
2018-10-10T11:39:29  <the-t-in-rtf> or in other words, once I get the hang of it.
2018-10-10T11:40:31  <jhernandez_> dandimitrov: sure, FYI tests are passing here
2018-10-10T11:40:35  <jhernandez_> ;)
2018-10-10T11:45:34  <dandimitrov> jhernandez_: Yep, but we’re writing more tests. We’re adressing comments from Bosmon in our PR
2018-10-10T11:46:20  <jhernandez_> dandimitrov: sure, in fact, I prefer to perform the updates on windows before shipping it into gpii-app
2018-10-10T11:49:34  <the-t-in-rtf> OK, I just confirmed that if I run the tests from c:/vagrant, I can't exit the shell afterwards.
2018-10-10T11:49:38  <the-t-in-rtf> let me try another little something.
2018-10-10T11:50:53  <the-t-in-rtf> I'm removing the posttest step temporarily to confirm that it's something in the main tests that leaves things in an unclean state.
2018-10-10T12:02:52  <the-t-in-rtf> OK, as I thought, it's the tests themselves that result in the shell not exiting, but only when running from c:/vagrant
2018-10-10T12:02:58  <the-t-in-rtf> so it's very much nothing to do with coverage
2018-10-10T12:03:11  <the-t-in-rtf> well, or at least not with reporting
2018-10-10T12:03:15  <the-t-in-rtf> I'll keep narrowing it down.
2018-10-10T12:03:26  <the-t-in-rtf> it might still be collecting coverage that's a problem.
2018-10-10T12:04:51  <georgitodorov> the-t-in-rtf: May I suggest something?
2018-10-10T12:05:02  <the-t-in-rtf> sure.
2018-10-10T12:06:18  <georgitodorov> the-t-in-rtf: Comment out these tests: https://github.com/danailbd/gpii-app/blob/feature/QSS1.1/tests/IntegrationTests.js#L122
2018-10-10T12:06:47  <georgitodorov> the-t-in-rtf: And line 117 and line 118
2018-10-10T12:07:06  <the-t-in-rtf> will do right after I finish the current experiment
2018-10-10T12:07:18  <the-t-in-rtf> seeing if it makes a difference running the raw source
2018-10-10T12:07:26  <georgitodorov> There is an issue where an Electron's webview is destroyed after its enwrapping BrowserWindow
2018-10-10T12:07:42  <georgitodorov> And that is why there are some "Object has been destroyed" errors when the tests finish
2018-10-10T12:08:03  <georgitodorov> It is a well-known Electron issue which has been resolved in later Electron releases
2018-10-10T12:08:28  <jhernandez_> hmmm
2018-10-10T12:09:26  <georgitodorov> the-t-in-rtf: Previously this wasn't an issue and the CI job was running fine. But it may be worth trying.
2018-10-10T12:10:01  <jhernandez_> I've tried to run the tests as CI does by changing into the v:\ folder and I'm getting the same hang
2018-10-10T12:10:15  <the-t-in-rtf> interesting.
2018-10-10T12:10:26  <jhernandez_> oh, and that's with electron 3
2018-10-10T12:10:29  <jhernandez_> georgitodorov: ^
2018-10-10T12:16:41  *** cindyli <cindyli!~Adium@67.216.44.39> has joined #fluid-work
2018-10-10T12:18:01  *** Justin_o <Justin_o!uid14648@gateway/web/irccloud.com/x-oizxcrhkkhbnyedi> has joined #fluid-work
2018-10-10T12:20:58  <the-t-in-rtf> Same here!  So, for those of you keeping score, the red herring pile now contains instrumentation, reporting, electron versions, and UNC paths.
2018-10-10T12:21:06  <the-t-in-rtf> @georgitodorov, trying your idea now.
2018-10-10T12:28:45  <cindyli> hi georgitodorov, i issued this pull request - https://github.com/GPII/universal/pull/684 to fix GPII-3437. it still needs more work on writing a test but what's in there should fix the problem. can you try it when you have a chance? thanks
2018-10-10T12:31:56  <georgitodorov> cindyli: Sure, I will give it a try shortly
2018-10-10T12:32:31  <cindyli> thanks, georgitodorov
2018-10-10T12:33:38  <the-t-in-rtf> @georgitodorov, it hangs even with those tests commented out.
2018-10-10T12:33:51  <the-t-in-rtf> Trying "the rule of halves" now to see if I can narrow it down.
2018-10-10T12:34:54  <georgitodorov> the-t-in-rtf: I see
2018-10-10T12:35:22  *** the-t-in-rtf <the-t-in-rtf!~Adium@212.78.169.180> has quit IRC (Quit: Leaving.)
2018-10-10T12:35:41  *** the-t-in-rtf <the-t-in-rtf!~Adium@212.78.169.180> has joined #fluid-work
2018-10-10T12:43:53  *** the-t-in-rtf <the-t-in-rtf!~Adium@212.78.169.180> has quit IRC (Quit: Leaving.)
2018-10-10T12:44:37  *** the-t-in-rtf <the-t-in-rtf!~Adium@212.78.169.180> has joined #fluid-work
2018-10-10T12:48:17  <the-t-in-rtf> well, that paid off.
2018-10-10T12:48:43  <the-t-in-rtf> npm run test:psp results in a window that won't exit.
2018-10-10T12:48:57  <the-t-in-rtf> I'll confirm that the other two phases of npm test work before narrowing things down further
2018-10-10T12:49:07  <the-t-in-rtf> it could still be something common to all the stages.
2018-10-10T12:52:24  <the-t-in-rtf> npm run gpii:testWindows doesn't result in a hang
2018-10-10T12:52:31  <the-t-in-rtf> now checking each part of test:psp
2018-10-10T12:56:10  <the-t-in-rtf> The first three test suites result in a hang, checking the second.
2018-10-10T12:59:09  <the-t-in-rtf> hmm, second three fail.
2018-10-10T12:59:22  <the-t-in-rtf> could be something with the harness itself, checking more variations.
2018-10-10T13:01:33  <the-t-in-rtf> could also be one or more tests in each half, sometimes you have to shuffle your definition of half to narrow things down.
2018-10-10T13:06:52  *** michelled <michelled!~Adium@205.211.168.102> has joined #fluid-work
2018-10-10T13:07:18  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has joined #fluid-work
2018-10-10T13:07:39  <the-t-in-rtf> looks like it's just the integration tests that result in a hang
2018-10-10T13:08:05  <the-t-in-rtf> or rather, that leave the shell in the state where it can't exit
2018-10-10T13:09:23  *** michelled <michelled!~Adium@205.211.168.102> has quit IRC (Client Quit)
2018-10-10T13:09:40  <georgitodorov> the-t-in-rtf: Thank you for looking into this. It's obviously not related to the coverage and we can examine it further
2018-10-10T13:09:54  <georgitodorov> What should we do in order to get the hand locally?
2018-10-10T13:10:10  <the-t-in-rtf> run the integration tests from either location then try to exit the shell
2018-10-10T13:10:12  *** michelled <michelled!~Adium@205.211.168.102> has joined #fluid-work
2018-10-10T13:10:27  <the-t-in-rtf> I'll keep narrowing it down until my next meeting, it's no trouble.
2018-10-10T13:10:55  <the-t-in-rtf> I mean, I can only get so involved in something big and then drop it for the meeting.
2018-10-10T13:10:58  *** colinclark <colinclark!~colinclar@205.211.168.103> has joined #fluid-work
2018-10-10T13:13:17  *** michelled <michelled!~Adium@205.211.168.102> has quit IRC (Client Quit)
2018-10-10T13:13:40  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has quit IRC (Quit: Leaving)
2018-10-10T13:14:11  *** simonjb <simonjb!~simonjb@198.178.118.18> has joined #fluid-work
2018-10-10T13:15:34  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has joined #fluid-work
2018-10-10T13:15:44  *** clown <clown!clown@nat/ocadu/x-bxrcletpkfdlckzf> has joined #fluid-work
2018-10-10T13:17:44  <georgitodorov> cindyli: I tested your fix and I the error message no longer appears. However, I observed something strange which I can't reproduce again.
2018-10-10T13:18:27  <georgitodorov> When I used "Reset all" for a profile that had all QSS settings changed (language, high contrast, DPI), the high contrast theme remained
2018-10-10T13:18:39  <georgitodorov> Even though the user was successfully keyed out
2018-10-10T13:19:15  <cindyli> which profile is it, georgitodorov
2018-10-10T13:19:25  <georgitodorov> But as I said - I can't reproduce it. Also, I think it may be something different which is not related to this issue
2018-10-10T13:19:35  <cindyli> oh, i see
2018-10-10T13:19:52  <georgitodorov> I used "snapset_1b" and added language, high contrast, etc, then saved and keyed out
2018-10-10T13:20:22  <cindyli> ok. let's keep an eye on it
2018-10-10T13:20:33  <georgitodorov> cindyli: I think we are good for now. If we find a consistent way to reproduce it, we will let you know
2018-10-10T13:20:48  <cindyli> cool. thanks, georgitodorov
2018-10-10T13:22:55  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has quit IRC (Quit: dandimitrov)
2018-10-10T13:23:13  *** michelled <michelled!~Adium@205.211.168.102> has joined #fluid-work
2018-10-10T13:23:23  *** michelled <michelled!~Adium@205.211.168.102> has quit IRC (Client Quit)
2018-10-10T13:23:50  <the-t-in-rtf> @georgitodorov, the problem is in the same neighbourhood, but the three tests you suggested commenting out are fine.
2018-10-10T13:23:58  <the-t-in-rtf> should have a clear culprit in a few minutes
2018-10-10T13:26:01  *** colinclark <colinclark!~colinclar@205.211.168.103> has quit IRC (Quit: colinclark)
2018-10-10T13:26:57  *** georgit <georgit!~georgitod@37.157.190.158> has joined #fluid-work
2018-10-10T13:28:02  *** colinclark <colinclark!~colinclar@205.211.168.103> has joined #fluid-work
2018-10-10T13:28:07  *** michelled <michelled!~Adium@205.211.168.102> has joined #fluid-work
2018-10-10T13:28:39  *** michelled <michelled!~Adium@205.211.168.102> has quit IRC (Client Quit)
2018-10-10T13:29:29  *** sepidehshahi <sepidehshahi!~sepidehsh@205.211.168.104> has joined #fluid-work
2018-10-10T13:30:03  *** georgitodorov <georgitodorov!~georgitod@37.157.190.158> has quit IRC (Ping timeout: 252 seconds)
2018-10-10T13:32:20  *** georgit <georgit!~georgitod@37.157.190.158> has quit IRC (Quit: Leaving)
2018-10-10T13:32:36  *** georgitodorov <georgitodorov!~georgitod@37.157.190.158> has joined #fluid-work
2018-10-10T13:39:14  <javjarfer[m]> <freenode_jhe "this is, not returning after tes"> I had the same results in windows until I used the CI environment
2018-10-10T13:40:34  <javjarfer[m]> Once I moved to execute the universal tests in the Fedora VM, errors went away
2018-10-10T14:02:43  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has joined #fluid-work
2018-10-10T14:22:41  *** michelled <michelled!~Adium@205.211.168.102> has joined #fluid-work
2018-10-10T14:27:14  *** michelled <michelled!~Adium@205.211.168.102> has quit IRC (Client Quit)
2018-10-10T14:27:19  *** georgitodorov <georgitodorov!~georgitod@37.157.190.158> has quit IRC (Quit: Leaving)
2018-10-10T14:41:31  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has quit IRC (Quit: dandimitrov)
2018-10-10T14:43:22  *** the-t-in-rtf <the-t-in-rtf!~Adium@212.78.169.180> has quit IRC (Quit: Leaving.)
2018-10-10T14:51:37  *** colinclark <colinclark!~colinclar@205.211.168.103> has quit IRC (Quit: colinclark)
2018-10-10T14:57:38  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has joined #fluid-work
2018-10-10T14:59:00  *** colinclark <colinclark!~colinclar@205.211.168.103> has joined #fluid-work
2018-10-10T14:59:30  *** sepidehshahi <sepidehshahi!~sepidehsh@205.211.168.104> has quit IRC (Quit: sepidehshahi)
2018-10-10T15:00:37  *** sepidehshahi <sepidehshahi!~sepidehsh@205.211.168.104> has joined #fluid-work
2018-10-10T15:00:45  *** michelled <michelled!~Adium@205.211.168.102> has joined #fluid-work
2018-10-10T15:03:46  *** michelled <michelled!~Adium@205.211.168.102> has quit IRC (Client Quit)
2018-10-10T15:07:15  *** the-t-in-rtf <the-t-in-rtf!~Adium@2a02:a210:2142:3480:fde3:15d4:d645:96fb> has joined #fluid-work
2018-10-10T15:32:29  *** colinclark <colinclark!~colinclar@205.211.168.103> has quit IRC (Quit: colinclark)
2018-10-10T15:39:25  <dandimitrov> Hey, jhernandez_, just to note that “hideQssSaveButton” is responsible for hiding the “Save button” in the QSS
2018-10-10T15:49:54  *** colinclark <colinclark!~colinclar@205.211.168.103> has joined #fluid-work
2018-10-10T15:58:46  *** yuriy <yuriy!~yuriy@37.157.190.158> has quit IRC (Quit: Leaving)
2018-10-10T15:59:50  <dandimitrov> (saw your comment in the Installer Fixes document)
2018-10-10T16:04:31  <jhernandez_> arch meeting guys
2018-10-10T16:04:54  <dandimitrov> jhernandez_: I tried your branch with the Electron 3.x and from what I’ve tested it works works great. The overall behaviour seems stable and there’s just a single failing test. Will be playing a bit more with it tomorrow
2018-10-10T16:05:36  *** colinclark <colinclark!~colinclar@205.211.168.103> has quit IRC (Quit: colinclark)
2018-10-10T16:07:49  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has quit IRC (Ping timeout: 246 seconds)
2018-10-10T16:08:39  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has joined #fluid-work
2018-10-10T16:09:45  *** dandimitrov <dandimitrov!~danailbd@37.157.190.158> has quit IRC (Quit: dandimitrov)
2018-10-10T16:10:37  *** colinclark <colinclark!~colinclar@205.211.168.103> has joined #fluid-work
2018-10-10T16:20:00  <Justin_o> fluid-everyone: reminder that the Community Meeting for today has been cancelled.
2018-10-10T16:36:52  *** colinclark <colinclark!~colinclar@205.211.168.103> has quit IRC (Quit: colinclark)
2018-10-10T16:57:53  *** colinclark <colinclark!~colinclar@205.211.168.103> has joined #fluid-work
2018-10-10T17:01:11  <the-t-in-rtf> @stegru, I will send you a branch link that you can pull the "break everything" changes from.
2018-10-10T17:01:34  <the-t-in-rtf> nearly done, just had to fire up a VM as it's not possible to run npm install from another platform.
2018-10-10T17:06:33  *** jhernandez <jhernandez!~jhernande@2a02:a03f:3ea7:d200:fc0f:927b:c0b0:ebb3> has joined #fluid-work
2018-10-10T17:08:34  <the-t-in-rtf> just confirming that it's suitably aflame before pushing it your way.
2018-10-10T17:12:33  <the-t-in-rtf> actually not all that flaming, more like a flaming cheeto than a flaming arrow.
2018-10-10T17:12:42  <the-t-in-rtf> six files need updating
2018-10-10T17:14:12  <the-t-in-rtf> https://github.com/the-t-in-rtf/windows/tree/this-is-fine
2018-10-10T17:14:19  <the-t-in-rtf> there you go @stegru
2018-10-10T17:17:12  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has quit IRC (Ping timeout: 252 seconds)
2018-10-10T17:19:41  <the-t-in-rtf> turn out I didn't have to do anything to my commit hooks because I had to disable them for windows
2018-10-10T17:19:49  <the-t-in-rtf> you can't run npm install from OS X
2018-10-10T17:20:01  <the-t-in-rtf> and hence you can't run grunt as part of a commit hook
2018-10-10T17:29:52  *** michelled <michelled!~Adium@205.211.168.102> has joined #fluid-work
2018-10-10T17:34:30  <Bosmon> colinclark, the-t-in-rtf, if you are interested - fresh release of my potentia II branch just now with a few bug fixes 3.0.0-dev.20181010T171529Z.aeaa6e324.FLUID-6148
2018-10-10T17:34:39  <Bosmon> Let me know if you get a chance to run any of your STUF with it
2018-10-10T17:34:45  <Bosmon> I'll try it again with gpii-universal now
2018-10-10T17:35:25  <colinclark> oh cool
2018-10-10T17:35:37  <colinclark> i'll try it with aconite when I get a spare sec
2018-10-10T17:35:42  <Bosmon> awesome!
2018-10-10T17:36:00  *** danayo <danayo!~danayo@205.211.168.104> has joined #fluid-work
2018-10-10T17:42:21  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has joined #fluid-work
2018-10-10T17:43:21  *** sepidehshahi <sepidehshahi!~sepidehsh@205.211.168.104> has quit IRC (Quit: sepidehshahi)
2018-10-10T17:45:33  *** michelled <michelled!~Adium@205.211.168.102> has quit IRC (Quit: Leaving.)
2018-10-10T17:47:49  *** sepidehshahi <sepidehshahi!~sepidehsh@205.211.168.104> has joined #fluid-work
2018-10-10T18:01:05  *** jhernandez <jhernandez!~jhernande@2a02:a03f:3ea7:d200:fc0f:927b:c0b0:ebb3> has quit IRC (Remote host closed the connection)
2018-10-10T18:03:23  *** sepidehshahi <sepidehshahi!~sepidehsh@205.211.168.104> has quit IRC (Quit: sepidehshahi)
2018-10-10T18:13:03  *** sepidehshahi <sepidehshahi!~sepidehsh@205.211.168.104> has joined #fluid-work
2018-10-10T18:44:33  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has quit IRC (Remote host closed the connection)
2018-10-10T18:44:53  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has joined #fluid-work
2018-10-10T19:11:34  *** colinclark <colinclark!~colinclar@205.211.168.103> has quit IRC (Quit: colinclark)
2018-10-10T19:14:49  *** colinclark <colinclark!~colinclar@205.211.168.103> has joined #fluid-work
2018-10-10T19:22:28  <sgithens> the-t-in-rtf:  Any idea why upgrading from gpii-handlebars 1.1.0 to 1.1.1 would cause "Assertion failure - check console for more details: Error in assembleCreatorArguments: cannot look up component type name gpii.handlebars.renderer.serverAware to a component creator grade with an argumentMap" If I go back to 1.1.0 it goes away.
2018-10-10T19:22:55  <sgithens> I tried moving back to the version of infusion in the handlebars package.json as well
2018-10-10T19:24:30  *** jhernandez_ <jhernandez_!~jhernande@2a02:a03f:3ea7:d200:78c2:67f9:e3a9:354c> has quit IRC (Ping timeout: 264 seconds)
2018-10-10T19:24:52  <sgithens> It looks like it might be coming from a gpii.handlebars.templateManager call in the client generated by the initBlock helper
2018-10-10T19:25:55  <sgithens> was about to finally move all my stuff over to the proper messageHelper
2018-10-10T19:26:38  *** colinclark <colinclark!~colinclar@205.211.168.103> has quit IRC (Quit: colinclark)
2018-10-10T19:27:13  <sgithens> hmm, I wonder if any of the html src includes moved around or got added between versions...
2018-10-10T19:28:14  *** colinclark <colinclark!~colinclar@205.211.168.103> has joined #fluid-work
2018-10-10T19:42:26  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has quit IRC (Remote host closed the connection)
2018-10-10T19:42:46  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has joined #fluid-work
2018-10-10T19:54:29  <the-t-in-rtf> @sgithens, you probably need to include the new "common" grade
2018-10-10T20:05:25  *** danayo <danayo!~danayo@205.211.168.104> has quit IRC (Quit: danayo)
2018-10-10T20:14:30  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has quit IRC (Ping timeout: 252 seconds)
2018-10-10T20:19:55  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has joined #fluid-work
2018-10-10T20:22:57  *** cindyli <cindyli!~Adium@67.216.44.39> has quit IRC (Quit: Leaving.)
2018-10-10T20:27:47  *** colinclark <colinclark!~colinclar@205.211.168.103> has quit IRC (Quit: colinclark)
2018-10-10T20:31:11  *** alanharnum <alanharnum!~alanharnu@205.211.168.101> has quit IRC (Quit: Leaving)
2018-10-10T20:31:43  *** colinclark <colinclark!~colinclar@205.211.168.103> has joined #fluid-work
2018-10-10T20:45:31  *** simonjb <simonjb!~simonjb@198.178.118.18> has quit IRC ()
2018-10-10T20:54:15  *** sepidehshahi <sepidehshahi!~sepidehsh@205.211.168.104> has quit IRC (Quit: sepidehshahi)
2018-10-10T21:06:02  *** clown <clown!clown@nat/ocadu/x-bxrcletpkfdlckzf> has quit IRC (Quit: Leaving.)
2018-10-10T21:08:27  *** cindyli <cindyli!~Adium@67.216.44.39> has joined #fluid-work
2018-10-10T21:10:03  *** danayo <danayo!~danayo@205.211.168.104> has joined #fluid-work
2018-10-10T21:10:17  *** danayo <danayo!~danayo@205.211.168.104> has quit IRC (Client Quit)
2018-10-10T21:24:27  *** cindyli <cindyli!~Adium@67.216.44.39> has quit IRC (Quit: Leaving.)
2018-10-10T21:46:11  <sgithens> the-t-in-rtf: thanks, adding in all the new src/js/common files fixed it.. get this now, so I imagien there are some new options I need to add to my defaults blocks or something:  Uncaught TypeError: Cannot read property 'deleteAndAddModelData' of undefined
2018-10-10T21:46:11  <sgithens>     at gpii.handlebars.renderer.serverAware.cacheTemplates (renderer.js:72)
2018-10-10T21:51:45  <sgithens> oops, missed a few more in common/lib, getting closer now with errors from my code
2018-10-10T22:07:51  <sgithens> it looks like maybe serverMessageAware is meant to replace the usage of templateAware
2018-10-10T22:10:27  <sgithens> but it doesn't seem to have a onMarkupRendered event
2018-10-10T22:19:47  <sgithens> moving back to templateAware... but it can't find my template.  I did try adding templateUrl: "/hbs" to the grade
2018-10-10T22:20:51  <sgithens> I'll back off to 1.1.0 and work on a few other things until we can touch base tomorrow
2018-10-10T22:46:11  *** colinclark <colinclark!~colinclar@205.211.168.103> has quit IRC (Quit: colinclark)
2018-10-10T22:56:51  *** Justin_o <Justin_o!uid14648@gateway/web/irccloud.com/x-oizxcrhkkhbnyedi> has quit IRC (Quit: Connection closed for inactivity)
